d_ff: 128
d_model: 768
batch_size: 512
lr: 1e-2
layers: 4
lr_patience: 100
scheduler: True
gpu: -1
name: both
max_epochs: -1
precision: 16
#size -> 20.6 million params
#37 iters on RTX8000 at fp32
